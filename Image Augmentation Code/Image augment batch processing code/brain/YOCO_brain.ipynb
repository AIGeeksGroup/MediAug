{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4812412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "def YOCO(images, aug_flip, aug_color, h, w):\n",
    "   \n",
    "    if torch.rand(1) > 0.5:\n",
    "        \n",
    "        left = aug_flip(images[:, :, :, 0:int(w/2)])\n",
    "        right = aug_color(images[:, :, :, int(w/2):w]) if torch.rand(1) > 0.5 else images[:, :, :, int(w/2):w]\n",
    "        images = torch.cat((left, right), dim=3)\n",
    "    else:\n",
    "        \n",
    "        top = aug_flip(images[:, :, 0:int(h/2), :])\n",
    "        bottom = aug_color(images[:, :, int(h/2):h, :]) if torch.rand(1) > 0.5 else images[:, :, int(h/2):h, :]\n",
    "        images = torch.cat((top, bottom), dim=2)\n",
    "    return images\n",
    "\n",
    "\n",
    "def augment_and_save(image_path, output_dir, aug_flip, aug_color):\n",
    "    \n",
    "    original_image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    transform_to_tensor = transforms.ToTensor()\n",
    "    original_tensor = transform_to_tensor(original_image).unsqueeze(0)  \n",
    "    _, _, h, w = original_tensor.shape\n",
    "\n",
    "    augmented_tensor = YOCO(original_tensor, aug_flip, aug_color, h, w)\n",
    "\n",
    "    transform_to_pil = transforms.ToPILImage()\n",
    "    augmented_image = transform_to_pil(augmented_tensor.squeeze(0))  \n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, os.path.basename(image_path))\n",
    "    augmented_image.save(output_path)\n",
    "\n",
    "def process_all_images(input_dir, output_dir, aug_flip, aug_color):\n",
    "   \n",
    "    for root, _, files in os.walk(input_dir):\n",
    "       \n",
    "        if os.path.basename(root) not in [\"glioma_tumor\", \"meningioma_tumor\", \"no_tumor\", \"pituitary_tumor\"]:\n",
    "            continue\n",
    "        \n",
    "        for file in tqdm(files, desc=f\"Processing {os.path.basename(root)}\"):\n",
    "            if file.endswith((\".jpg\", \".jpeg\", \".png\")):  \n",
    "                image_path = os.path.join(root, file)\n",
    "                \n",
    "                \n",
    "                relative_path = os.path.relpath(root, input_dir)\n",
    "                save_dir = os.path.join(output_dir, relative_path, \"YOCO\")\n",
    "                \n",
    "                \n",
    "                augment_and_save(image_path, save_dir, aug_flip, aug_color)\n",
    "\n",
    "input_dir = \"/content/drive/My Drive/MRI/Training\"\n",
    "output_dir = \"/content/drive/My Drive/MRI/Training\"\n",
    "\n",
    "aug_flip = torch.nn.Sequential(\n",
    "    transforms.RandomHorizontalFlip(p=1.0)  \n",
    ")\n",
    "\n",
    "aug_color = torch.nn.Sequential(\n",
    "    transforms.ColorJitter(\n",
    "        brightness=0.5,  \n",
    "        contrast=0.5,    \n",
    "        saturation=0.5   \n",
    "    )\n",
    ")\n",
    "\n",
    "process_all_images(input_dir, output_dir, aug_flip, aug_color)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
